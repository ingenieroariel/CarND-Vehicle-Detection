{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from skimage.feature import hog\n",
    "\n",
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Drawing bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def draw_boxes(img, boxes, color=(0, 0, 255), thick=6):\n",
    "    \"\"\"Draws bounding boxes on an image.\"\"\"\n",
    "    # Make a copy of the image\n",
    "    draw_img = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in boxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(draw_img, bbox[0], bbox[1], color, thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return draw_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features\n",
    "    \n",
    "    \n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(img, size).ravel() \n",
    "    # Return the feature vector\n",
    "    return features\n",
    "\n",
    "\n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features\n",
    "\n",
    "\n",
    "def hog_features(img, color_space='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                        spatial_feat=True, hist_feat=True, hog_feat=True):    \n",
    "    #1) Define an empty list to receive features\n",
    "    img_features = []\n",
    "    #2) Apply color conversion if other than 'RGB'\n",
    "    if color_space != 'RGB':\n",
    "        if color_space == 'HSV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        elif color_space == 'LUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "        elif color_space == 'HLS':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        elif color_space == 'YUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "        elif color_space == 'YCrCb':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    else: feature_image = np.copy(img)      \n",
    "    #3) Compute spatial features if flag is set\n",
    "    if spatial_feat == True:\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        #4) Append features to list\n",
    "        img_features.append(spatial_features)\n",
    "    #5) Compute histogram features if flag is set\n",
    "    if hist_feat == True:\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "        #6) Append features to list\n",
    "        img_features.append(hist_features)\n",
    "    #7) Compute HOG features if flag is set\n",
    "    if hog_feat == True:\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_features.extend(get_hog_features(feature_image[:,:,channel], \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=False, feature_vec=True))      \n",
    "        else:\n",
    "            hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                        pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "        #8) Append features to list\n",
    "        img_features.append(hog_features)\n",
    "\n",
    "    #9) Return concatenated array of features\n",
    "    return np.concatenate(img_features)\n",
    "\n",
    "def extract_features_set(list_images_set, color_space='RGB',\n",
    "                    spatial_size=(32, 32), hist_bins=32,\n",
    "                    hist_range=(0, 256), orient=9,\n",
    "                    pix_per_cell=8, cell_per_block=2,\n",
    "                    hog_channel=0, spatial_feat=True,\n",
    "                    hist_feat=True, hog_feat=True):\n",
    "    data_features = []\n",
    "    for each_path in list_images_set:\n",
    "        img = cv2.imread(each_path)\n",
    "        data_features.append(hog_features(img, color_space=color_space,\n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins,\n",
    "                            orient=orient, pix_per_cell=pix_per_cell,\n",
    "                            cell_per_block=cell_per_block,\n",
    "                            hog_channel=hog_channel, spatial_feat=spatial_feat,\n",
    "                            hist_feat=hist_feat, hog_feat=hog_feat))\n",
    "    return data_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# function to get a set of features and put them into a list\n",
    "def extract_features(list_images_set, color_space='RGB',\n",
    "                    spatial_size=(32, 32), hist_bins=32,\n",
    "                    hist_range=(0, 256), orient=9,\n",
    "                    pix_per_cell=8, cell_per_block=2,\n",
    "                    hog_channel=0, spatial_feat=True,\n",
    "                    hist_feat=True, hog_feat=True):\n",
    "    data_features = []\n",
    "    for each_path in list_images_set:\n",
    "        img = cv2.imread(each_path)\n",
    "        data_features.append(hog_features(img, color_space=color_space,\n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins,\n",
    "                            orient=orient, pix_per_cell=pix_per_cell,\n",
    "                            cell_per_block=cell_per_block,\n",
    "                            hog_channel=hog_channel, spatial_feat=spatial_feat,\n",
    "                            hist_feat=hist_feat, hog_feat=hog_feat))\n",
    "    return data_features\n",
    "\n",
    "\n",
    "# function to prepare dataset, it returns the features and the labels\n",
    "def get_data(vehicle_path, non_vehicle_path, take_pos = 0, take_neg = 0):\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    x_data_car = []\n",
    "    y_data_car = []\n",
    "    x_data_nocar = []\n",
    "    y_data_nocar = []\n",
    "    im_v = glob.glob(vehicle_path + '/*')\n",
    "    list_path_images = []\n",
    "    for each_folder in im_v:\n",
    "        im_list = glob.glob(each_folder + '/*')\n",
    "        list_path_images = list_path_images + list(im_list)\n",
    "        \n",
    "    for each_path in list_path_images:\n",
    "        #img = cv2.imread(each_path)\n",
    "        #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        #img_feature = single_img_features(img)\n",
    "        #x_data_car.append(img_feature)\n",
    "        x_data_car.append(each_path)\n",
    "        y_data_car.append(1)\n",
    "    \n",
    "    im_nv = glob.glob(non_vehicle_path + '/*')\n",
    "    list_path_images = []\n",
    "    for each_folder in im_nv:\n",
    "        im_list = glob.glob(each_folder + '/*')\n",
    "        list_path_images = list_path_images + list(im_list)\n",
    "    for each_path in list_path_images:\n",
    "        #img = cv2.imread(each_path)\n",
    "        #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        #img_feature = single_img_features(img)\n",
    "        #x_data_nocar.append(img_feature)\n",
    "        x_data_nocar.append(each_path)\n",
    "        y_data_nocar.append(0)\n",
    "\n",
    "        \n",
    "    \n",
    "    if take_pos != 0:\n",
    "        random.shuffle(x_data_car)\n",
    "        \n",
    "        x_data = x_data_car[:int(take_pos)] \n",
    "        y_data = y_data_car[:int(take_pos)] \n",
    "        \n",
    "    else:\n",
    "        x_data = x_data_car\n",
    "        y_data = y_data_car\n",
    "        \n",
    "    print 'positive', len(x_data)\n",
    "    \n",
    "    if take_neg != 0:\n",
    "        random.shuffle(x_data_nocar)\n",
    "        x_data = x_data + x_data_nocar[:int(take_neg)]\n",
    "        y_data = y_data + y_data_nocar[:int(take_neg)]\n",
    "    else:\n",
    "        x_data = x_data + x_data_nocar\n",
    "        y_data = y_data + y_data_no_car\n",
    "        \n",
    "    print 'positive + negative', len(x_data)\n",
    "    \n",
    "    return x_data, y_data\n",
    "\n",
    "def save_svm(model_filename='model.pickle', scaler_filename='scaler.pickle'):\n",
    "    my_x, my_y = get_data('vehicles/', 'non-vehicles/', take_pos=600, take_neg=600)\n",
    "    # extract_features from list of images and these parameters\n",
    "\n",
    "    color_space = 'YCrCb' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "    orient = 13  # HOG orientations\n",
    "    pix_per_cell = 8 # HOG pixels per cell\n",
    "    cell_per_block = 2 # HOG cells per block\n",
    "    hog_channel = 'ALL' # Can be 0, 1, 2, or \"ALL\"\n",
    "    spatial_size = (16, 16) # Spatial binning dimensions\n",
    "    hist_bins = 16    # Number of histogram bins\n",
    "    spatial_feat = True # Spatial features on or off\n",
    "    hist_feat = False # Histogram features on or off\n",
    "    hog_feat = True # HOG features on or off\n",
    "    data_feats = extract_features(my_x, color_space=color_space,\n",
    "                                spatial_size=spatial_size, hist_bins=hist_bins,\n",
    "                                orient=orient, pix_per_cell=pix_per_cell,\n",
    "                                cell_per_block=cell_per_block,\n",
    "                                hog_channel=hog_channel, spatial_feat=spatial_feat,\n",
    "                                hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "    X_scaler = RobustScaler().fit(data_feats)\n",
    "    scaled_X = X_scaler.transform(data_feats)\n",
    "    rand_state = np.random.randint(0, 100)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(scaled_X, my_y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "    k=5\n",
    "    svc = LinearSVC(C=10**k)\n",
    "    t=time.time()\n",
    "    svc.fit(X_train, y_train)\n",
    "    t2 = time.time()\n",
    "    print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "    \n",
    "    print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "    \n",
    "    with open('model.pickle', 'wb') as output:\n",
    "        pickle.dump(svc, output, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    with open('scaler.pickle', 'wb') as output:\n",
    "        pickle.dump(X_scaler, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    \n",
    "    \n",
    "def get_svm(filename='model.pickle'):\n",
    "    # SVM classifier\n",
    "    with open(filename, 'rb') as in_path:\n",
    "        svc_model = pickle.load(in_path)\n",
    "\n",
    "    return svc_model\n",
    "\n",
    "def get_scaler(filename='scaler.pickle'):\n",
    "    with open(filename, 'rb') as in_path:\n",
    "        scaler = pickle.load(in_path)\n",
    "    return scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive 600\n",
      "positive + negative 1200\n",
      "(3.15, 'Seconds to train SVC...')\n",
      "('Test Accuracy of SVC = ', 0.9875)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=100000, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_svm()\n",
    "get_svm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def slide_window(img, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                    xy_window=(64, 64), xy_overlap=(0.2, 0.2)):\n",
    "    \n",
    "    # If x and/or y start/stop positions not defined, set to image size\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    # Compute the number of windows in x/y\n",
    "    nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))\n",
    "    ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))\n",
    "    nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step) \n",
    "    ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step) \n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    # Loop through finding x and y window positions\n",
    "    # Note: you could vectorize this step, but in practice\n",
    "    # you'll be considering windows one by one with your\n",
    "    # classifier, so looping makes sense\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            # Calculate window position\n",
    "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "            endx = startx + xy_window[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "            endy = starty + xy_window[1]\n",
    "            # Append window position to list\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "    # Return the list of windows\n",
    "    return window_list\n",
    "\n",
    "\n",
    "def search_windows(img, windows, clf, scaler, color_space='RGB',\n",
    "                    spatial_size=(32, 32), hist_bins=32,\n",
    "                    hist_range=(0, 256), orient=9,\n",
    "                    pix_per_cell=8, cell_per_block=2,\n",
    "                    hog_channel=0, spatial_feat=True,\n",
    "                    hist_feat=True, hog_feat=True):\n",
    "    #1) Create an empty list to receive positive detection windows\n",
    "    on_windows = []\n",
    "    #2) Iterate over all windows in the list\n",
    "    for window in windows:\n",
    "        #3) Extract the test window from original image\n",
    "        test_img = cv2.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], (64, 64))      \n",
    "        #4) Extract features for that window using single_img_features()\n",
    "        features = hog_features(test_img, color_space=color_space, \n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                            orient=orient, pix_per_cell=pix_per_cell, \n",
    "                            cell_per_block=cell_per_block, \n",
    "                            hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                            hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "        #5) Scale extracted features to be fed to classifier\n",
    "        test_features = scaler.transform(np.array(features).reshape(1, -1))\n",
    "        #6) Predict using your classifier\n",
    "        prediction = clf.decision_function(test_features)\n",
    "        #7) If positive (prediction == 1) then save the window\n",
    "        if prediction > -0.03:\n",
    "            on_windows.append(window)\n",
    "    #8) Return windows for positive detections\n",
    "    return on_windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def add_heat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "    # Return updated heatmap\n",
    "    return heatmap# Iterate through list of bboxes\n",
    "\n",
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap\n",
    "\n",
    "def draw_heatmap(img, hot_windows):\n",
    "\n",
    "    heat = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "    \n",
    "    # Add heat to each box in box list\n",
    "    heat = add_heat(heat, hot_windows)\n",
    "    \n",
    "    # Apply threshold to help remove false positives\n",
    "    heat = apply_threshold(heat, 1)\n",
    "\n",
    "    return heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the image\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "global boxes_circular_queue\n",
    "\n",
    "\n",
    "boxes_circular_queue = deque([], maxlen=5)\n",
    "\n",
    "\n",
    "def temporal_filter(boxes):\n",
    "    boxes_circular_queue.append(boxes)\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def pipeline(img, y_start_stop=(350, 650), xy_window=(96, 96), xy_overlap=(0.75, 0.75), scale=1.4,\n",
    "             color_space='YCrCb', spatial_size=(16, 16), hist_bins=16, orient=13, pix_per_cell=8,\n",
    "             cell_per_block=2, hog_channel='ALL', spatial_feat=True, hist_feat=False, hog_feat=True): \n",
    "\n",
    "    raw_windows = slide_window(img, x_start_stop=[None, None], y_start_stop=y_start_stop, \n",
    "                        xy_window=xy_window, xy_overlap=xy_overlap)\n",
    "\n",
    "    svc_model = get_svm()\n",
    "    scaler = get_scaler()\n",
    "    \n",
    "    hot_windows = search_windows(img, raw_windows, svc_model, scaler, color_space=color_space, \n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                            orient=orient, pix_per_cell=pix_per_cell, \n",
    "                            cell_per_block=cell_per_block, \n",
    "                            hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                            hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "    \n",
    "    \n",
    "    with_raw_windows = draw_boxes(img, raw_windows)\n",
    "    \n",
    "    with_hot_windows = draw_boxes(img, hot_windows)\n",
    "\n",
    "    heat = draw_heatmap(img, hot_windows)\n",
    "    \n",
    "    labels = label(heat)\n",
    "    \n",
    "    with_labels = draw_labeled_bboxes(np.copy(img), labels)\n",
    "\n",
    "    time_labels = temporal_filter(labels)\n",
    "    \n",
    "    with_time = draw_labeled_bboxes(np.copy(img), time_labels)\n",
    "    \n",
    "    output = np.zeros((1080, 1800, 3), dtype=np.uint8)\n",
    "    \n",
    "    output[360:1080, 0:1200] = cv2.resize(img, (1200,720), interpolation=cv2.INTER_AREA) \n",
    "\n",
    "    output[0:360, 0:600] = cv2.resize(with_raw_windows, (600,360), interpolation=cv2.INTER_AREA)   \n",
    "\n",
    "    output[0:360, 600:1200] = cv2.resize(with_hot_windows, (600,360), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    output[0:360, 1200:1800] = cv2.resize(np.dstack((heat*20, heat*20, heat*30)), (600,360), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    output[360:720,1200:1800] = cv2.resize(with_labels, (600,360), interpolation=cv2.INTER_AREA) \n",
    "\n",
    "    output[720:1080,1200:1800] = cv2.resize(with_time, (600,360), interpolation=cv2.INTER_AREA) \n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video result.mp4\n",
      "[MoviePy] Writing video result.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 38/39 [03:00<00:04,  4.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: result.mp4 \n",
      "\n",
      "CPU times: user 2min 35s, sys: 4.23 s, total: 2min 40s\n",
      "Wall time: 3min 8s\n"
     ]
    }
   ],
   "source": [
    "white_output = 'result.mp4'\n",
    "clip1 = VideoFileClip(\"test_video.mp4\")\n",
    "white_clip = clip1.fl_image(pipeline)\n",
    "\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"900\" height=\"540\" controls>\n",
       "  <source src=\"result.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"900\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
